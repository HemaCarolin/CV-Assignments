{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCapture a 10 sec video footage using a camera of your choice.\\nThe footage should be taken with the camera in hand and you need to pan the camera slightly from left-right or right-left during the 10 sec duration. \\nPick any image frame from the 10 sec video footage. \\nPick a region of interest corresponding to an object in the image. \\nCrop this region from the image. \\nThen use this cropped region to compare with randomly picked 10 images in the dataset of 10 sec video frames, to see if there is a match for the object in the scenes from the 10 images. \\nFor comparison use sum of squared differences (SSD) or normalized correlation.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Capture a 10 sec video footage using a camera of your choice.\n",
    "The footage should be taken with the camera in hand and you need to pan the camera slightly from left-right or right-left during the 10 sec duration. \n",
    "Pick any image frame from the 10 sec video footage. \n",
    "Pick a region of interest corresponding to an object in the image. \n",
    "Crop this region from the image. \n",
    "Then use this cropped region to compare with randomly picked 10 images in the dataset of 10 sec video frames, to see if there is a match for the object in the scenes from the 10 images. \n",
    "For comparison use sum of squared differences (SSD) or normalized correlation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start defining a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define a source - left grayscale cameras\n",
    "cam_left = pipeline.createMonoCamera()\n",
    "cam_left.setBoardSocket(dai.CameraBoardSocket.CAM_B)\n",
    "cam_left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "# Create outputs\n",
    "xout_left = pipeline.createXLinkOut()\n",
    "xout_left.setStreamName('left')\n",
    "cam_left.out.link(xout_left.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RECORDING FOR 10 SECONDS\n",
    "## THE FRAMES ARE BEING STORED IN DIRECTORY \"video_frames\"\n",
    "\n",
    "# Connect and start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "\n",
    "    # Output queue will be used to get the grayscale frames from the output defined above\n",
    "    q = device.getOutputQueue(name=\"left\", maxSize=4, blocking=False)\n",
    "\n",
    "    # Make sure the destination path is present before starting to store the examples\n",
    "    Path(f\"../video_frames/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # running loop for 10 secs\n",
    "    ten_secs = time.time() + 10\n",
    "    \n",
    "    while time.time() < ten_secs:\n",
    "        # Blocking call, will wait until a new data has arrived\n",
    "        inSrc = q.get()  \n",
    "        # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "        frame = inSrc.getCvFrame()\n",
    "        # Frame is transformed and ready to be shown\n",
    "        cv2.imshow(\"left\", frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        cv2.imwrite(f\"../video_frames/{int(time.time() * 10000)}.png\", frame)\n",
    "\n",
    "    cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the region of interest \n",
    "# roi.png is selected and cropped\n",
    "roi = cv2.imread(\"../video_frames/roi.png\")\n",
    "roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Region of interest', roi)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"pattern_match_ssd\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(10):\n",
    "    # loading a random image\n",
    "    rand_img_file = random.choice(os.listdir(\"../video_frames/\"))\n",
    "    rand_img = cv2.imread(\"../video_frames/\"+rand_img_file)\n",
    "    gray = cv2.cvtColor(rand_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create Summed of Squared Differences with patch\n",
    "    ssd = cv2.matchTemplate(gray, roi, cv2.TM_SQDIFF_NORMED)\n",
    "\n",
    "    # find min for match with SQDIFF_NORMED\n",
    "    point = np.where(ssd == ssd.min())\n",
    "    y = point[0][0]\n",
    "    x = point[1][0]\n",
    "    w = len(roi[0])\n",
    "    l = len(roi)\n",
    "\n",
    "    # Draw Rectangle\n",
    "    pm = cv2.rectangle(rand_img, (x, y), (x+w, y+l), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Pattern Match\", pm) \n",
    "    cv2.waitKey(1000)\n",
    "    cv2.imwrite(\"pattern_match_ssd/out_\"+rand_img_file, pm)\n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"pattern_match_ncor\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(10):\n",
    "    # loading a random image\n",
    "    rand_img_file = random.choice(os.listdir(\"../video_frames/\"))\n",
    "    rand_img = cv2.imread(\"./video_frames/\"+rand_img_file)\n",
    "    gray = cv2.cvtColor(rand_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create Summed of Squared Differences with patch\n",
    "    ssd = cv2.matchTemplate(gray, roi, cv2.TM_SQDIFF_NORMED)\n",
    "\n",
    "    # find min for match with SQDIFF_NORMED\n",
    "    point = np.where(ssd == ssd.min())\n",
    "    y = point[0][0]\n",
    "    x = point[1][0]\n",
    "    w = len(roi[0])\n",
    "    l = len(roi)\n",
    "\n",
    "    # Draw Rectangle\n",
    "    pm = cv2.rectangle(rand_img, (x, y), (x+w, y+l), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Pattern Match\", pm) \n",
    "    cv2.waitKey(1000)\n",
    "    cv2.imwrite(\"pattern_match_ncor/out_\"+rand_img_file, pm)\n",
    "    cv2.destroyAllWindows()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
